{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Smart Watch Sleep Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project,Various machine learning models were explored to predict Smart Watch Sleep Scores based on nearly one year of sleep score data. The exploration involved comparing the accuracies of these different models and investigating the feature importances within each model.ng to apply various Machine Learning models to predict Smartwatch Sleep Scores based on a sample of almost one year of sleep score data. We will compare the accuracies of teh different models and look into the feature importances in each of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/kalyanpeta/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/kalyanpeta/anaconda3/lib/python3.11/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Users/kalyanpeta/anaconda3/lib/python3.11/site-packages (from xgboost) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the app data\n",
    "sleep_stats_data = pd.read_csv('sleep_stats.csv')\n",
    "\n",
    "# Import the score data\n",
    "sleep_score_data = pd.read_csv('sleep_score.csv').iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start Time</td>\n",
       "      <td>End Time</td>\n",
       "      <td>Minutes Asleep</td>\n",
       "      <td>Minutes Awake</td>\n",
       "      <td>Number of Awakenings</td>\n",
       "      <td>Time in Bed</td>\n",
       "      <td>Minutes REM Sleep</td>\n",
       "      <td>Minutes Light Sleep</td>\n",
       "      <td>Minutes Deep Sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01 10:05PM</td>\n",
       "      <td>2020-07-02 6:23AM</td>\n",
       "      <td>456</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>498</td>\n",
       "      <td>94</td>\n",
       "      <td>271</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-30 9:43PM</td>\n",
       "      <td>2020-07-01 6:03AM</td>\n",
       "      <td>412</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>79</td>\n",
       "      <td>208</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-29 10:03PM</td>\n",
       "      <td>2020-06-30 5:57AM</td>\n",
       "      <td>412</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>473</td>\n",
       "      <td>91</td>\n",
       "      <td>242</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-28 11:24PM</td>\n",
       "      <td>2020-06-29 6:05AM</td>\n",
       "      <td>342</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>401</td>\n",
       "      <td>71</td>\n",
       "      <td>196</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sleep         Unnamed: 1      Unnamed: 2     Unnamed: 3  \\\n",
       "0          Start Time           End Time  Minutes Asleep  Minutes Awake   \n",
       "1  2020-07-01 10:05PM  2020-07-02 6:23AM             456             42   \n",
       "2   2020-06-30 9:43PM  2020-07-01 6:03AM             412             88   \n",
       "3  2020-06-29 10:03PM  2020-06-30 5:57AM             412             61   \n",
       "4  2020-06-28 11:24PM  2020-06-29 6:05AM             342             59   \n",
       "\n",
       "             Unnamed: 4   Unnamed: 5         Unnamed: 6           Unnamed: 7  \\\n",
       "0  Number of Awakenings  Time in Bed  Minutes REM Sleep  Minutes Light Sleep   \n",
       "1                    37          498                 94                  271   \n",
       "2                    32          500                 79                  208   \n",
       "3                    26          473                 91                  242   \n",
       "4                    26          401                 71                  196   \n",
       "\n",
       "           Unnamed: 8  \n",
       "0  Minutes Deep Sleep  \n",
       "1                  91  \n",
       "2                 125  \n",
       "3                  79  \n",
       "4                  75  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first rows of the sleep stats DataFrame\n",
    "sleep_stats_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <th>Minutes Light Sleep</th>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01 10:05PM</td>\n",
       "      <td>2020-07-02 6:23AM</td>\n",
       "      <td>456</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>498</td>\n",
       "      <td>94</td>\n",
       "      <td>271</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-30 9:43PM</td>\n",
       "      <td>2020-07-01 6:03AM</td>\n",
       "      <td>412</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>79</td>\n",
       "      <td>208</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-29 10:03PM</td>\n",
       "      <td>2020-06-30 5:57AM</td>\n",
       "      <td>412</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>473</td>\n",
       "      <td>91</td>\n",
       "      <td>242</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-28 11:24PM</td>\n",
       "      <td>2020-06-29 6:05AM</td>\n",
       "      <td>342</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>401</td>\n",
       "      <td>71</td>\n",
       "      <td>196</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-27 10:42PM</td>\n",
       "      <td>2020-06-28 9:20AM</td>\n",
       "      <td>530</td>\n",
       "      <td>108</td>\n",
       "      <td>39</td>\n",
       "      <td>638</td>\n",
       "      <td>98</td>\n",
       "      <td>305</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2019-07-12 11:11PM</td>\n",
       "      <td>2019-07-13 7:05AM</td>\n",
       "      <td>423</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>474</td>\n",
       "      <td>89</td>\n",
       "      <td>263</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2019-07-11 9:58PM</td>\n",
       "      <td>2019-07-12 8:23AM</td>\n",
       "      <td>540</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>625</td>\n",
       "      <td>114</td>\n",
       "      <td>324</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2019-07-10 9:43PM</td>\n",
       "      <td>2019-07-11 7:32AM</td>\n",
       "      <td>525</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>589</td>\n",
       "      <td>93</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2019-07-09 9:12PM</td>\n",
       "      <td>2019-07-10 7:31AM</td>\n",
       "      <td>536</td>\n",
       "      <td>83</td>\n",
       "      <td>38</td>\n",
       "      <td>619</td>\n",
       "      <td>124</td>\n",
       "      <td>336</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2019-07-07 10:53PM</td>\n",
       "      <td>2019-07-08 5:42AM</td>\n",
       "      <td>372</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>408</td>\n",
       "      <td>84</td>\n",
       "      <td>245</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0            Start Time           End Time Minutes Asleep Minutes Awake  \\\n",
       "1    2020-07-01 10:05PM  2020-07-02 6:23AM            456            42   \n",
       "2     2020-06-30 9:43PM  2020-07-01 6:03AM            412            88   \n",
       "3    2020-06-29 10:03PM  2020-06-30 5:57AM            412            61   \n",
       "4    2020-06-28 11:24PM  2020-06-29 6:05AM            342            59   \n",
       "5    2020-06-27 10:42PM  2020-06-28 9:20AM            530           108   \n",
       "..                  ...                ...            ...           ...   \n",
       "318  2019-07-12 11:11PM  2019-07-13 7:05AM            423            51   \n",
       "319   2019-07-11 9:58PM  2019-07-12 8:23AM            540            85   \n",
       "320   2019-07-10 9:43PM  2019-07-11 7:32AM            525            64   \n",
       "321   2019-07-09 9:12PM  2019-07-10 7:31AM            536            83   \n",
       "322  2019-07-07 10:53PM  2019-07-08 5:42AM            372            36   \n",
       "\n",
       "0   Number of Awakenings Time in Bed Minutes REM Sleep Minutes Light Sleep  \\\n",
       "1                     37         498                94                 271   \n",
       "2                     32         500                79                 208   \n",
       "3                     26         473                91                 242   \n",
       "4                     26         401                71                 196   \n",
       "5                     39         638                98                 305   \n",
       "..                   ...         ...               ...                 ...   \n",
       "318                   28         474                89                 263   \n",
       "319                   30         625               114                 324   \n",
       "320                   31         589                93                 322   \n",
       "321                   38         619               124                 336   \n",
       "322                   29         408                84                 245   \n",
       "\n",
       "0   Minutes Deep Sleep  \n",
       "1                   91  \n",
       "2                  125  \n",
       "3                   79  \n",
       "4                   75  \n",
       "5                  127  \n",
       "..                 ...  \n",
       "318                 71  \n",
       "319                102  \n",
       "320                110  \n",
       "321                 76  \n",
       "322                 43  \n",
       "\n",
       "[322 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the first row the column headers\n",
    "sleep_stats_data.columns = sleep_stats_data.iloc[0]\n",
    "\n",
    "# Drop the first row from the DataFrame\n",
    "sleep_stats_data.drop(sleep_stats_data.index[0], inplace=True)\n",
    "sleep_stats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 1 to 322\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Start Time            322 non-null    object\n",
      " 1   End Time              322 non-null    object\n",
      " 2   Minutes Asleep        322 non-null    object\n",
      " 3   Minutes Awake         322 non-null    object\n",
      " 4   Number of Awakenings  322 non-null    object\n",
      " 5   Time in Bed           322 non-null    object\n",
      " 6   Minutes REM Sleep     287 non-null    object\n",
      " 7   Minutes Light Sleep   287 non-null    object\n",
      " 8   Minutes Deep Sleep    287 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 22.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Obtain some information about the DataFrame\n",
    "sleep_stats_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <th>Minutes Light Sleep</th>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2020-04-16 2:09PM</td>\n",
       "      <td>2020-04-16 3:27PM</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-03-22 1:47PM</td>\n",
       "      <td>2020-03-22 3:21PM</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-03-11 4:19PM</td>\n",
       "      <td>2020-03-11 5:24PM</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2020-03-06 3:40PM</td>\n",
       "      <td>2020-03-06 4:40PM</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2020-02-23 2:28PM</td>\n",
       "      <td>2020-02-23 3:42PM</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0           Start Time           End Time Minutes Asleep Minutes Awake  \\\n",
       "77   2020-04-16 2:09PM  2020-04-16 3:27PM             76             2   \n",
       "103  2020-03-22 1:47PM  2020-03-22 3:21PM             83             1   \n",
       "115  2020-03-11 4:19PM  2020-03-11 5:24PM             55             6   \n",
       "121  2020-03-06 3:40PM  2020-03-06 4:40PM             53             7   \n",
       "134  2020-02-23 2:28PM  2020-02-23 3:42PM             68             5   \n",
       "\n",
       "0   Number of Awakenings Time in Bed Minutes REM Sleep Minutes Light Sleep  \\\n",
       "77                     0          78               NaN                 NaN   \n",
       "103                    1          93               NaN                 NaN   \n",
       "115                    1          65               NaN                 NaN   \n",
       "121                    0          60               NaN                 NaN   \n",
       "134                    0          74               NaN                 NaN   \n",
       "\n",
       "0   Minutes Deep Sleep  \n",
       "77                 NaN  \n",
       "103                NaN  \n",
       "115                NaN  \n",
       "121                NaN  \n",
       "134                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first five rows with missing values\n",
    "sleep_stats_data[sleep_stats_data['Minutes REM Sleep'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection and by having a close look at start and finishing times for the sleep stats with NaNs for REM, Light and Deep sleep we see that these data points refer to afternoon naps. These should be excluded from our data set as they do not have a sleep score or the necessary sleep stats attached to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs\n",
    "sleep_stats_data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns 2-8 to data type float\n",
    "cols_to_convert = sleep_stats_data.columns[2:]\n",
    "sleep_stats_data[cols_to_convert] = sleep_stats_data[cols_to_convert].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 287 entries, 1 to 322\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Start Time            287 non-null    object \n",
      " 1   End Time              287 non-null    object \n",
      " 2   Minutes Asleep        287 non-null    float64\n",
      " 3   Minutes Awake         287 non-null    float64\n",
      " 4   Number of Awakenings  287 non-null    float64\n",
      " 5   Time in Bed           287 non-null    float64\n",
      " 6   Minutes REM Sleep     287 non-null    float64\n",
      " 7   Minutes Light Sleep   287 non-null    float64\n",
      " 8   Minutes Deep Sleep    287 non-null    float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 22.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sleep_stats_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-02T06:23:30Z</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01T06:03:30Z</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-30T05:57:00Z</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-29T06:05:00Z</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-28T09:20:30Z</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp  overall_score\n",
       "0  2020-07-02T06:23:30Z             86\n",
       "1  2020-07-01T06:03:30Z             77\n",
       "2  2020-06-30T05:57:00Z             78\n",
       "3  2020-06-29T06:05:00Z             76\n",
       "4  2020-06-28T09:20:30Z             82"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first rows of the sleep score DataFrame\n",
    "sleep_score_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   timestamp      286 non-null    object\n",
      " 1   overall_score  286 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the summary for the sleep score df\n",
    "sleep_score_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the two DataFrames on the date, the first step involves addressing the slight differences in how the times are displayed. Since the sleep_stat DataFrame contains both starting and ending dates but we are interested in the ending dates (those corresponding to the dates on which the sleep score is provided), we will drop the beginning date column. Then, we will transform the dates so that they are in the same format across both DataFrames. Finally, we can proceed to merge the DataFrames on the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop start time column from sleep_stat\n",
    "sleep_stats_data.drop(columns='Start Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate date into new column\n",
    "sleep_stats_data['Date'] = sleep_stats_data['End Time'].apply(lambda x: x[:10])\n",
    "sleep_score_data['Date'] = sleep_score_data.timestamp.apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End Time</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <th>Minutes Light Sleep</th>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "      <th>Date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-02 6:23AM</td>\n",
       "      <td>456.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-07-02T06:23:30Z</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01 6:03AM</td>\n",
       "      <td>412.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>2020-07-01T06:03:30Z</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-30 5:57AM</td>\n",
       "      <td>412.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>2020-06-30T05:57:00Z</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-29 6:05AM</td>\n",
       "      <td>342.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>2020-06-29T06:05:00Z</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-28 9:20AM</td>\n",
       "      <td>530.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>2020-06-28T09:20:30Z</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            End Time  Minutes Asleep  Minutes Awake  Number of Awakenings  \\\n",
       "0  2020-07-02 6:23AM           456.0           42.0                  37.0   \n",
       "1  2020-07-01 6:03AM           412.0           88.0                  32.0   \n",
       "2  2020-06-30 5:57AM           412.0           61.0                  26.0   \n",
       "3  2020-06-29 6:05AM           342.0           59.0                  26.0   \n",
       "4  2020-06-28 9:20AM           530.0          108.0                  39.0   \n",
       "\n",
       "   Time in Bed  Minutes REM Sleep  Minutes Light Sleep  Minutes Deep Sleep  \\\n",
       "0        498.0               94.0                271.0                91.0   \n",
       "1        500.0               79.0                208.0               125.0   \n",
       "2        473.0               91.0                242.0                79.0   \n",
       "3        401.0               71.0                196.0                75.0   \n",
       "4        638.0               98.0                305.0               127.0   \n",
       "\n",
       "         Date             timestamp  overall_score  \n",
       "0  2020-07-02  2020-07-02T06:23:30Z           86.0  \n",
       "1  2020-07-01  2020-07-01T06:03:30Z           77.0  \n",
       "2  2020-06-30  2020-06-30T05:57:00Z           78.0  \n",
       "3  2020-06-29  2020-06-29T06:05:00Z           76.0  \n",
       "4  2020-06-28  2020-06-28T09:20:30Z           82.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames\n",
    "joined_data = sleep_stats_data.merge(sleep_score_data, on='Date', how='left')\n",
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns\n",
    "sleep_data = joined_data.drop(columns=['End Time', 'timestamp', 'Date', 'Number of Awakenings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop last nan\n",
    "sleep_data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <th>Minutes Light Sleep</th>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Minutes Asleep  Minutes Awake  Time in Bed  Minutes REM Sleep  \\\n",
       "0           456.0           42.0        498.0               94.0   \n",
       "1           412.0           88.0        500.0               79.0   \n",
       "2           412.0           61.0        473.0               91.0   \n",
       "3           342.0           59.0        401.0               71.0   \n",
       "4           530.0          108.0        638.0               98.0   \n",
       "\n",
       "   Minutes Light Sleep  Minutes Deep Sleep  overall_score  \n",
       "0                271.0                91.0           86.0  \n",
       "1                208.0               125.0           77.0  \n",
       "2                242.0                79.0           78.0  \n",
       "3                196.0                75.0           76.0  \n",
       "4                305.0               127.0           82.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first five rows\n",
    "sleep_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sleep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the relationships between features and sleep score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the analysis and construction of Machine Learning models, it's imperative to examine the relationship that each individual feature has with the overall sleep score. This step provides insight into the impact of each feature on the sleep score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the scatterplots of the relationships between all independent variables and the dependent\n",
    "# variable\n",
    "def plot_relationships(df, num_cols):\n",
    "    variables = df.columns\n",
    "    # This function assumes that the dependent variable is in the last column\n",
    "    dep_var = variables[-1]\n",
    "    ind_var = variables[:-1]\n",
    "    figs = len(dep_var)\n",
    "    num_cols = num_cols\n",
    "    num_rows = round(figs / num_cols) + 1\n",
    "    fig = 1\n",
    "    plt.figure(figsize=(20,30))\n",
    "    # Loop through all independent variables and create the scatter plot\n",
    "    for i in ind_var:\n",
    "        pltfignums = [str(num_rows), str(num_cols), str(fig)]\n",
    "        pltfig = int(''.join(pltfignums))\n",
    "        plt.subplot(pltfig)\n",
    "        plt.scatter(df[i], df[dep_var])\n",
    "        plt.xlabel(str(i))\n",
    "        plt.ylabel(str(dep_var))\n",
    "        fig +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x3000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the function with the reduced app data DataFrame and subplots in a grid of two columns\n",
    "plot_relationships(sleep_data, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken by themselves, Minutes Asleep and Minutes REM Sleep seem to have the strongest positive relationships with the overall sleep score. Generally speaking this makes sense because more time in bed should lead to more sleep, and therefore more quality sleep, and REM sleep has been found to be extremely important for many restorative functions and memory formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(sleep_data.corr(), annot=True, cmap='coolwarm', fmt='.2g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect sleep score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find spread of sleep score values\n",
    "spread = int(max(sleep_data.overall_score) - min(sleep_data.overall_score))\n",
    "spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14bd03210>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sleep score histogram and its mean\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist(sleep_data.overall_score, bins=spread)\n",
    "plt.axvline(sleep_data.overall_score.mean(), color='r', label='Average Sleep Score')\n",
    "plt.xlabel('Sleep Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sleep Score Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of sleep scores is skewed to the left. This makes sense because bad night sleeps are more likely to occur than exceptionally good ones due to multiple reasons such as staying out late, having to gte up extremely early, etc. Given that the average sleep score in the data set is already relatively high at 82 and the upper limit being 100, it is by definition difficult to have many outliers that lie above the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many online data science projects, a well-separated training set and test set are provided, ensuring that the variable to be predicted is excluded from the test set to prevent spillover effects. This allows for the training set to be further split into training and validation sets without concern for data leakage. However, relying solely on the data obtained from Smart Watch, we must partition the data into training, validation, and test sets ourselves. One common and straightforward approach is to use the train_test_split function twice.\n",
    "\n",
    "Moreover, when constructing Machine Learning models, it's crucial to prevent information about the test (and validation) data from leaking into the training stage. Since scaling features involves incorporating information about the data used for scaling (e.g., mean, variance, maximum, or minimum values), it's essential to separate the test and validation sets from the training set before scaling the data. Therefore, before proceeding further, the data is split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform first split\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(sleep_data.iloc[:,:-1], \n",
    "                                                              sleep_data['overall_score'], test_size=0.2, \n",
    "                                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the second split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 57, 58)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths of the different subsets\n",
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_valid.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training set, validation set and test set we can proceed as follows: Train models on the training data, measure their accuracy on the validation data, tweak the model to be more accurate and measure the new accuracy, once we're happy with its performance we measure its generalisability on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.boxplot(data=X_train.iloc[:,1:], orient='h', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although for the Machine Learning Models in this project feature scaling is not required, it is considered best practice to scale features when comparing different models and their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47416413,  0.32      ,  0.45801527,  0.53125   ,  0.44032922,\n",
       "         0.49193548],\n",
       "       [ 0.71732523,  0.11      ,  0.60814249,  0.725     ,  0.63374486,\n",
       "         0.50806452],\n",
       "       [ 0.23100304,  0.33      ,  0.25699746,  0.38125   ,  0.49382716,\n",
       "        -0.06451613],\n",
       "       [ 0.21276596,  0.3       ,  0.23409669,  0.4375    ,  0.21399177,\n",
       "         0.36290323],\n",
       "       [ 0.24924012,  0.67      ,  0.35877863,  0.43125   ,  0.10699588,\n",
       "         0.67741935],\n",
       "       [ 0.11246201,  0.44      ,  0.18575064, -0.03125   ,  0.34567901,\n",
       "         0.44354839],\n",
       "       [ 0.62006079,  0.51      ,  0.62849873,  0.525     ,  0.59670782,\n",
       "         0.58064516],\n",
       "       [ 0.70212766,  0.48      ,  0.68956743,  0.55      ,  0.51028807,\n",
       "         0.93548387],\n",
       "       [ 0.17021277,  0.17      ,  0.1653944 ,  0.2625    ,  0.12345679,\n",
       "         0.65322581],\n",
       "       [ 0.39209726,  0.36      ,  0.39949109,  0.50625   ,  0.35802469,\n",
       "         0.46774194],\n",
       "       [ 0.38297872,  0.33      ,  0.38422392,  0.475     ,  0.24691358,\n",
       "         0.7016129 ],\n",
       "       [ 0.56231003,  0.57      ,  0.59541985,  0.35625   ,  0.67489712,\n",
       "         0.49193548],\n",
       "       [ 0.58054711,  0.47      ,  0.58524173,  0.65      ,  0.49382716,\n",
       "         0.51612903],\n",
       "       [ 0.42857143,  0.27      ,  0.40712468,  0.3375    ,  0.44032922,\n",
       "         0.62096774],\n",
       "       [ 0.52583587,  0.36      ,  0.51145038,  0.68125   ,  0.37860082,\n",
       "         0.55645161],\n",
       "       [ 0.42553191,  0.19      ,  0.38422392,  0.45      ,  0.35802469,\n",
       "         0.62903226],\n",
       "       [ 0.58662614,  0.72      ,  0.65394402,  0.375     ,  0.69135802,\n",
       "         0.5       ],\n",
       "       [ 0.24012158,  0.43      ,  0.29007634,  0.29375   ,  0.26748971,\n",
       "         0.51612903],\n",
       "       [ 0.53495441,  0.32      ,  0.50890585,  0.51875   ,  0.35802469,\n",
       "         0.83064516],\n",
       "       [ 0.00607903,  0.08      ,  0.00508906,  0.325     ,  0.0617284 ,\n",
       "         0.25806452],\n",
       "       [ 0.31610942,  0.24      ,  0.30534351,  0.475     ,  0.21399177,\n",
       "         0.58870968],\n",
       "       [ 0.44072948,  0.19      ,  0.39694656,  0.675     ,  0.14403292,\n",
       "         0.7983871 ],\n",
       "       [ 0.20364742,  0.25      ,  0.21374046,  0.2625    ,  0.11111111,\n",
       "         0.76612903],\n",
       "       [ 0.20972644,  0.3       ,  0.23155216,  0.2375    ,  0.30452675,\n",
       "         0.43548387],\n",
       "       [ 0.62917933,  0.39      ,  0.60559796,  0.575     ,  0.65843621,\n",
       "         0.41935484],\n",
       "       [ 0.67781155,  0.7       ,  0.72519084,  0.9125    ,  0.43209877,\n",
       "         0.55645161],\n",
       "       [ 0.45896657,  0.32      ,  0.44529262,  0.4375    ,  0.48559671,\n",
       "         0.48387097],\n",
       "       [ 0.55319149,  0.23      ,  0.50127226,  0.6125    ,  0.36213992,\n",
       "         0.75      ],\n",
       "       [ 0.78723404,  0.53      ,  0.7735369 ,  0.99375   ,  0.31687243,\n",
       "         0.96774194],\n",
       "       [ 0.39513678,  0.22      ,  0.36641221,  0.4625    ,  0.43621399,\n",
       "         0.37903226],\n",
       "       [ 0.11854103,  0.25      ,  0.14249364,  0.31875   ,  0.1399177 ,\n",
       "         0.41129032],\n",
       "       [ 0.59574468,  0.36      ,  0.56997455,  0.5       ,  0.53497942,\n",
       "         0.66935484],\n",
       "       [ 0.3343465 ,  0.16      ,  0.30025445,  0.74375   ,  0.00823045,\n",
       "         0.69354839],\n",
       "       [ 0.32218845,  0.47      ,  0.36895674,  0.325     ,  0.28395062,\n",
       "         0.66129032],\n",
       "       [ 0.27963526,  0.36      ,  0.30534351,  0.3375    ,  0.32510288,\n",
       "         0.4516129 ],\n",
       "       [ 0.05775076,  0.22      ,  0.08396947,  0.2125    ,  0.14403292,\n",
       "         0.37903226],\n",
       "       [ 0.40729483,  0.6       ,  0.47328244,  0.275     ,  0.43621399,\n",
       "         0.65322581],\n",
       "       [ 0.68085106,  0.54      ,  0.6870229 ,  0.55625   ,  0.61728395,\n",
       "         0.66129032],\n",
       "       [ 0.44984802,  0.6       ,  0.50890585,  0.26875   ,  0.44444444,\n",
       "         0.75806452],\n",
       "       [ 0.60486322,  0.43      ,  0.59541985,  0.6875    ,  0.48559671,\n",
       "         0.5483871 ],\n",
       "       [ 0.53191489,  0.74      ,  0.61323155,  0.4625    ,  0.67901235,\n",
       "         0.26612903],\n",
       "       [ 0.28571429,  0.53      ,  0.35368957,  0.55      ,  0.10288066,\n",
       "         0.62903226],\n",
       "       [ 0.41641337,  0.12      ,  0.35877863,  0.45625   ,  0.33744856,\n",
       "         0.63709677],\n",
       "       [ 0.3100304 ,  0.09      ,  0.26208651,  0.40625   ,  0.218107  ,\n",
       "         0.65322581],\n",
       "       [ 0.51671733,  0.27      ,  0.48091603,  0.5375    ,  0.55555556,\n",
       "         0.37096774],\n",
       "       [ 0.58966565,  0.47      ,  0.59287532,  0.725     ,  0.39506173,\n",
       "         0.63709677],\n",
       "       [ 0.07294833,  0.15      ,  0.07888041,  0.39375   , -0.02469136,\n",
       "         0.51612903],\n",
       "       [ 0.443769  ,  0.44      ,  0.46310433,  0.14375   ,  0.67489712,\n",
       "         0.4516129 ],\n",
       "       [ 0.48328267,  0.52      ,  0.51653944,  0.35      ,  0.39917695,\n",
       "         0.83064516],\n",
       "       [ 0.25531915,  0.31      ,  0.27226463,  0.36875   ,  0.30041152,\n",
       "         0.39516129],\n",
       "       [ 0.3100304 ,  0.45      ,  0.35368957,  0.325     ,  0.21399177,\n",
       "         0.76612903],\n",
       "       [ 0.6443769 ,  0.39      ,  0.61832061,  0.43125   ,  0.85185185,\n",
       "         0.26612903],\n",
       "       [ 0.00607903,  0.22      ,  0.04071247,  0.0375    ,  0.25102881,\n",
       "         0.25806452],\n",
       "       [ 0.35866261,  0.22      ,  0.33587786,  0.3625    ,  0.34979424,\n",
       "         0.58064516],\n",
       "       [ 0.31610942,  0.38      ,  0.34096692,  0.55625   ,  0.15226337,\n",
       "         0.60483871],\n",
       "       [ 0.79331307,  0.6       ,  0.79643766,  0.8125    ,  0.3909465 ,\n",
       "         1.07258065],\n",
       "       [ 0.61398176,  0.27      ,  0.56234097,  0.56875   ,  0.56378601,\n",
       "         0.57258065],\n",
       "       [ 0.29179331,  0.5       ,  0.35114504,  0.26875   ,  0.45679012,\n",
       "         0.31451613]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scaler with object range of 0-1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform using the training data\n",
    "scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test features\n",
    "scaler.transform(X_valid)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a linear regression minimises a loss function by choosing coefficients for each feature variable. One problem with that is that large coefficients can lead to overfitting, meaning that the model will perform well on the training data but poorly on data it has never seen before. This is where regularisation comes in. Essentially, you just alter the loss function to penalise large coefficients. Lasso Regression, unlike the closely related Ridge Regression, can be used to select important features of a dataset. This is because it tends tos hrink the coefficients of less important features to close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lasso coefficients for sleep data features')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the coefficients\n",
    "lasso_coef = lasso.coef_\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(X_train.columns)), lasso_coef)\n",
    "plt.xticks(range(len(X_train.columns)), X_train.columns, rotation=60)\n",
    "plt.axhline(0.0, linestyle='--', color='r')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso coefficients for sleep data features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso Regression algorithm has effectively reduced the coefficients of Time in Bed and Minutes Light Sleep to close to zero, indicating their lesser importance compared to the other four features. This reduction proves advantageous as including all features would likely lead to significant multicollinearity issues. While multicollinearity itself may not hinder predictive power, it severely complicates the interpretation of the model. Hence, for the sake of building Machine Learning models that are both effective and interpretable, reducing multicollinearity is imperative.\n",
    "\n",
    "For subsequent analysis, we will focus solely on including Minutes Asleep, Minutes Awake, Minutes REM Sleep, and Minutes Deep Sleep as features in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns to drop\n",
    "cols_to_drop = ['Time in Bed', 'Minutes Light Sleep']\n",
    "\n",
    "# Drop these columns from training, validation and test data\n",
    "X_train_temp.drop(columns=cols_to_drop, inplace=True)\n",
    "X_train.drop(columns=cols_to_drop, inplace=True)\n",
    "X_valid.drop(columns=cols_to_drop, inplace=True)\n",
    "X_test.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining performance measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance measures we want to use to compare the different ML models are Accuracy and Score. Average Error is added to the list as an extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    mae = mean_absolute_error(test_labels, predictions)\n",
    "    mse = mean_squared_error(test_labels, predictions)\n",
    "    r2 = r2_score(test_labels, predictions)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Mean Absolute Error: {:0.4f}.'.format(mae))\n",
    "    print('Mean Squared Error: {:0.4f}.'.format(mse))\n",
    "    print('R^2 Score = {:0.4f}.'.format(r2))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is typically used as a performance measure in classification problems and not regression problems because it refers to the proportion of correct predictions that the model makes. The ways we use accuracy for the regression models in this analysis is different. Accuracy for the regression models is a measure of how far off (in percentage terms) the prediction in sleep score will be from the actual sleep score, on average. For example, if the actual sleep score is 80 and the model has an accuracy of 96%, meaning that on average it is 4% off, the model is expected to make a prediction for the sleep score in the range of 76.8 (80 - (80 x 0.04)) to 83.2 (80 + (80 x 0.04)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline that we will compare the performance of the Machine Learning models against will be simply predicting the average Sleep Score every night. A good model should be substantially better than just predicting the average every night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Mean Absolute Error: 5.4912.\n",
      "Mean Squared Error: 47.9474.\n",
      "R^2 Score = -0.1037.\n",
      "Accuracy = 92.68%.\n"
     ]
    }
   ],
   "source": [
    "# Create list of median predictions that has the same length as y_valid\n",
    "baseline_y = [y_train.median()] * len(y_valid)\n",
    "\n",
    "# Compute the relevant scores\n",
    "base_predictions = baseline_y\n",
    "base_mae = mean_absolute_error(y_valid, base_predictions)\n",
    "base_mse = mean_squared_error(y_valid, base_predictions)\n",
    "base_r2 = r2_score(y_valid, base_predictions)\n",
    "base_errors = abs(base_predictions - y_valid)\n",
    "base_mape = 100 * np.mean(base_errors / y_valid)\n",
    "base_accuracy = 100 - base_mape\n",
    "print('Model Performance')\n",
    "print('Mean Absolute Error: {:0.4f}.'.format(base_mae))\n",
    "print('Mean Squared Error: {:0.4f}.'.format(base_mse))\n",
    "print('R^2 Score = {:0.4f}.'.format(base_r2))\n",
    "print('Accuracy = {:0.2f}%.'.format(base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we would like to use is MLR. we used MLR in another project to understand the relationship between the independent variables and the sleep score. This time, we will use it to make predictions about sleep scores and test the accuracy of this linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regressor\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Fit MLR model to training data\n",
    "mlr = regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Mean Absolute Error: 2.5870.\n",
      "Mean Squared Error: 10.5967.\n",
      "R^2 Score = 0.7561.\n",
      "Accuracy = 96.63%.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "scoring(mlr, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>overall_score</td>  <th>  R-squared:         </th> <td>   0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   81.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>3.60e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:27:54</td>     <th>  Log-Likelihood:    </th> <td> -408.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   171</td>      <th>  AIC:               </th> <td>   826.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   166</td>      <th>  BIC:               </th> <td>   842.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   59.5066</td> <td>    1.614</td> <td>   36.864</td> <td> 0.000</td> <td>   56.319</td> <td>   62.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minutes Asleep</th>     <td>    0.0389</td> <td>    0.005</td> <td>    7.925</td> <td> 0.000</td> <td>    0.029</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minutes Awake</th>      <td>   -0.1018</td> <td>    0.015</td> <td>   -6.847</td> <td> 0.000</td> <td>   -0.131</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minutes REM Sleep</th>  <td>    0.0793</td> <td>    0.011</td> <td>    7.307</td> <td> 0.000</td> <td>    0.058</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Minutes Deep Sleep</th> <td>    0.0357</td> <td>    0.011</td> <td>    3.395</td> <td> 0.001</td> <td>    0.015</td> <td>    0.056</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.143</td> <th>  Durbin-Watson:     </th> <td>   1.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.010</td> <th>  Jarque-Bera (JB):  </th> <td>   9.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.535</td> <th>  Prob(JB):          </th> <td>  0.0108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.355</td> <th>  Cond. No.          </th> <td>3.98e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.98e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &  overall\\_score  & \\textbf{  R-squared:         } &     0.663   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.655   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     81.60   \\\\\n",
       "\\textbf{Date:}              & Mon, 22 Apr 2024 & \\textbf{  Prob (F-statistic):} &  3.60e-38   \\\\\n",
       "\\textbf{Time:}              &     17:27:54     & \\textbf{  Log-Likelihood:    } &   -408.37   \\\\\n",
       "\\textbf{No. Observations:}  &         171      & \\textbf{  AIC:               } &     826.7   \\\\\n",
       "\\textbf{Df Residuals:}      &         166      & \\textbf{  BIC:               } &     842.4   \\\\\n",
       "\\textbf{Df Model:}          &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}              &      59.5066  &        1.614     &    36.864  &         0.000        &       56.319    &       62.694     \\\\\n",
       "\\textbf{Minutes Asleep}     &       0.0389  &        0.005     &     7.925  &         0.000        &        0.029    &        0.049     \\\\\n",
       "\\textbf{Minutes Awake}      &      -0.1018  &        0.015     &    -6.847  &         0.000        &       -0.131    &       -0.072     \\\\\n",
       "\\textbf{Minutes REM Sleep}  &       0.0793  &        0.011     &     7.307  &         0.000        &        0.058    &        0.101     \\\\\n",
       "\\textbf{Minutes Deep Sleep} &       0.0357  &        0.011     &     3.395  &         0.001        &        0.015    &        0.056     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  9.143 & \\textbf{  Durbin-Watson:     } &    1.963  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.010 & \\textbf{  Jarque-Bera (JB):  } &    9.051  \\\\\n",
       "\\textbf{Skew:}          & -0.535 & \\textbf{  Prob(JB):          } &   0.0108  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.355 & \\textbf{  Cond. No.          } & 3.98e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 3.98e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          overall_score   R-squared:                       0.663\n",
       "Model:                            OLS   Adj. R-squared:                  0.655\n",
       "Method:                 Least Squares   F-statistic:                     81.60\n",
       "Date:                Mon, 22 Apr 2024   Prob (F-statistic):           3.60e-38\n",
       "Time:                        17:27:54   Log-Likelihood:                -408.37\n",
       "No. Observations:                 171   AIC:                             826.7\n",
       "Df Residuals:                     166   BIC:                             842.4\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 59.5066      1.614     36.864      0.000      56.319      62.694\n",
       "Minutes Asleep         0.0389      0.005      7.925      0.000       0.029       0.049\n",
       "Minutes Awake         -0.1018      0.015     -6.847      0.000      -0.131      -0.072\n",
       "Minutes REM Sleep      0.0793      0.011      7.307      0.000       0.058       0.101\n",
       "Minutes Deep Sleep     0.0357      0.011      3.395      0.001       0.015       0.056\n",
       "==============================================================================\n",
       "Omnibus:                        9.143   Durbin-Watson:                   1.963\n",
       "Prob(Omnibus):                  0.010   Jarque-Bera (JB):                9.051\n",
       "Skew:                          -0.535   Prob(JB):                       0.0108\n",
       "Kurtosis:                       3.355   Cond. No.                     3.98e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.98e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the statsmodel results\n",
    "X_mlr = sm.add_constant(X_train)\n",
    "est = sm.OLS(y_train, X_mlr)\n",
    "est2 = est.fit()\n",
    "est2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients in our model are close to those of the MLR using the entire dataset. Looking at the feature importances in combination with the sign of the coefficients provides an important insight ignoring multicollinearity. Minutes Awake seem to have the biggest impact on sleep score and because that variable has a negative coefficient, it's impact is a sleep score reducing one. Disregarding multicollinearity, these feature importances indicate that it takes more than two minutes of REM sleep to make up for one minute of being awake. Furthermore, REM sleep appears to be almost twice as important as deep sleep when it comes to their impact on sleep score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit RF model to training data\n",
    "rf = rf_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Mean Absolute Error: 2.5875.\n",
      "Mean Squared Error: 11.3915.\n",
      "R^2 Score = 0.7378.\n",
      "Accuracy = 96.58%.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "scoring(rf, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14e7cde50>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = rf.predict(X_valid)\n",
    "\n",
    "x = np.linspace(65, 90, 25)\n",
    "y = x\n",
    "\n",
    "plt.scatter(y_pred, y_valid)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <td>0.479255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes Awake</th>\n",
       "      <td>0.111434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <td>0.326952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "      <td>0.082359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature Importance\n",
       "Minutes Asleep                0.479255\n",
       "Minutes Awake                 0.111434\n",
       "Minutes REM Sleep             0.326952\n",
       "Minutes Deep Sleep            0.082359"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of the feature importances \n",
    "rf_feats = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=['Feature Importance'])\n",
    "rf_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a random forest regression, feature importance represents a measure of how much a feature decreases impurity in the set decision trees. Remember that at every node in a tree the data has to be split so that similar value sof dependent variables end up in the same set after the split, thereby decreasing the impurity. For classification problems, the measure of impurity is called Gini Impurity, which is absed on information gain, and for regression problems the measure of impurity is variance. In a random forest regression, therefore, a more important feature is one that leads to a split in the dataset that leads to a strong decrease in variance.\n",
    "\n",
    "Minutes REM sleep appears to be the feature that decreases impurity the most, followed by Time in Bed and then Minutes Awake and Minutes Deep Sleep. \n",
    "\n",
    "In this model, we have to be careful and not attach too much value to the feature importances of the model. The reason is that the features are correlated and therefore once one of the features is used as a predictor the importance of the others will automatically be reduced since a lot of the impurity that they could have removed is already removed by the feature that was considered before them and is highly correlated to them.\n",
    "\n",
    "Next, let's look at Extreme Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regressor\n",
    "xgb_regressor = XGBRegressor(random_state=42)\n",
    "\n",
    "# Fit model to training data\n",
    "xgb = xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Mean Absolute Error: 2.9554.\n",
      "Mean Squared Error: 14.5202.\n",
      "R^2 Score = 0.6657.\n",
      "Accuracy = 96.11%.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "scoring(xgb, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <td>0.346840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes Awake</th>\n",
       "      <td>0.147533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <td>0.406932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "      <td>0.098696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature Importance\n",
       "Minutes Asleep                0.346840\n",
       "Minutes Awake                 0.147533\n",
       "Minutes REM Sleep             0.406932\n",
       "Minutes Deep Sleep            0.098696"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to inspect the feature importances again\n",
    "xgb_feats = pd.DataFrame(xgb.feature_importances_, index=X_train.columns, columns=['Feature Importance'])\n",
    "xgb_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, Minutes REM Sleep is by far the most important feature again and, similar to the Random Forest, Time in Bed is the second most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because We are using a relatively small dataset of sleep scores and related features, a simple train test split may lead to over- or underfitting, meaning that the model may be either fitted too well to the training data or not well enough. One solution to this potential problem is to use Cross Validation. The general concept of Cross Validation is similar to that of splitting the data into training and testing data and can be thought of as a repeated train test split with subsequent testing of the model accuracy. In a train test split you train the model on one subset of the data and test it on the remaining data but you do that only once. In Cross Validation you perform multiple train test splits and for each split the test and training data are different. Basically, you split the data into a number of subsets, called folds, hold out one set at a time, train the model on the remaining data and test it on the hold out set. You repeat these steps until you have used every subset as the test set, i.e. by definition the number of times you perform these steps is equal to the number of folds you split the dataset into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models to be tested\n",
    "mlr_reg = LinearRegression()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = xgb_regressor = XGBRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the models in a list to be used for cross validation\n",
    "models = [mlr_reg, rf_reg, xgb_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares the CV perfromance of a set of predetrmined models \n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    maes = []\n",
    "    mses = []\n",
    "    r2s = []\n",
    "    accs = []\n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of all CVs to the list\n",
    "    for model in models:\n",
    "        mae = -np.round(cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv), 4)\n",
    "        maes.append(mae)\n",
    "        mae_avg = round(mae.mean(), 4)\n",
    "        mse = -np.round(cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv), 4)\n",
    "        mses.append(mse)\n",
    "        mse_avg = round(mse.mean(), 4)\n",
    "        r2 = np.round(cross_val_score(model, X, y, scoring='r2', cv=cv), 4)\n",
    "        r2s.append(r2)\n",
    "        r2_avg = round(r2.mean(), 4)\n",
    "        acc = np.round((100 - (100 * (mae * len(X))) / sum(y)), 4)\n",
    "        accs.append(acc)\n",
    "        acc_avg = round(acc.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [mae_avg, mse_avg, r2_avg, acc_avg]\n",
    "    cv_accuracies.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return cv_accuracies, maes, mses, r2s, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comp, maes, mses, r2s, accs = cv_comparison(models, X_train_temp, y_train_temp, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Multiple Linear Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>2.2869</td>\n",
       "      <td>2.1735</td>\n",
       "      <td>2.3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>8.3989</td>\n",
       "      <td>7.8714</td>\n",
       "      <td>9.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.6882</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>97.1982</td>\n",
       "      <td>97.3371</td>\n",
       "      <td>97.0948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Multiple Linear Regression  Random Forest  \\\n",
       "Mean Absolute Error                      2.2869         2.1735   \n",
       "Mean Squared Error                       8.3989         7.8714   \n",
       "R^2                                      0.6882         0.7011   \n",
       "Accuracy                                97.1982        97.3371   \n",
       "\n",
       "                     Extreme Gradient Boosting  \n",
       "Mean Absolute Error                     2.3713  \n",
       "Mean Squared Error                      9.9675  \n",
       "R^2                                     0.6190  \n",
       "Accuracy                               97.0948  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the columns of the compariosn table and return it\n",
    "comp.columns = ['Multiple Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, compared to the results achieved with one simple train test split, MLR has the highest R^2 and Random Forest ha sthe lowest. Let's have a closer look at the R^2 of every fold of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Fold</th>\n",
       "      <th>2nd Fold</th>\n",
       "      <th>3rd Fold</th>\n",
       "      <th>4th Fold</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multiple Linear Regression</th>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.6882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.7939</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.7011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.6190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            1st Fold  2nd Fold  3rd Fold  4th Fold  Average\n",
       "Multiple Linear Regression    0.6750    0.6722    0.7003    0.7053   0.6882\n",
       "Random Forest                 0.5632    0.7025    0.7939    0.7449   0.7011\n",
       "Extreme Gradient Boosting     0.4605    0.6520    0.6347    0.7288   0.6190"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame for all R^2s\n",
    "r2_comp = pd.DataFrame(r2s, index=comp.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', '4th Fold'])\n",
    "\n",
    "# Add a column for the averages\n",
    "r2_comp['Average'] = np.round(r2_comp.mean(axis=1),4)\n",
    "r2_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above table shows, R^2s fluctuate a lot depending on which subset is used as the holdout set, i.e. the validation set and which ones are used as the training sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Machine Learning models have hyperparameters, which can be tweaked to reach more optimal performace of the model. Scikit-Learn provides sensible defaults for these hyperparameters but there is no one-size-fits-all. Figuring out good hyperparameters in theory is nearly impossible which is why the best and fastest way to optimise hyperparameters is through experiments.\n",
    "\n",
    "Hyperparameter tuning builds on the concept of cross-validation in order to account for overfitting. Just like for model evaluation itself, if we tried to optimise the hyperparameters used in a model solely on one pair of training and validation data we may tune the hyperparameters in a way that fits the model extremely well to the one validation set but the model may perform poorly when applied beyond the validation set. Cross-validation takes car eof this problem.\n",
    "\n",
    "More specifically, the type of hyperparameter tuning that we will use is called \"Random Search Cross Validation\". Essentially, how this works is we first define a range of values for the hyperparamaters that we would like to tune. We then combine all the ranges for the hyperparameters we want to tune in a grid. The Random Search Cross Validation then picks random values from that grid, uses them as the values for the hyperparameters, runs a cross validation using the model with the randomly selected hyperparameters and evaluate sthe resulting score. We can specify how many random cross validations we want to include, keeping in mind that more random cross validations increase the likelihood of finding optimal hyperparameters but are also take more time and computational power. \n",
    "\n",
    "Because the Multiple Linear regression model technically does not have hyperparameters that we can optimise, I will focus on the hyperparameters of the Random Forest and the Extreme Gradient Boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can set up ranges of values for the different hyperparameters we need to decide which hyperparemeters we want to try and optimise. A good place to start is to look at the official documentation (LINK) and think about which hyperparameters could be important for our model.\n",
    "\n",
    "We will try to adjust the following hyperparameters: n_estimators, max_features, max_depth, criterion, min_samples_split, bootstrap, min_impurity_decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]\n",
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['squared_error', 'absolute_error']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1500, 2000],\n",
       " 'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, None],\n",
       " 'max_features': ['sqrt', 'log2'],\n",
       " 'criterion': ['squared_error', 'absolute_error'],\n",
       " 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " 'min_impurity_decrease': [0.0, 0.05, 0.1],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}\n",
    "\n",
    "rf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search across 200 different combinations, meaning that a total of 600 models will be evaluated (3 folds for 200 combinations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                      &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30, 35,\n",
       "                                                      40, 45, 50, 55, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_impurity_decrease&#x27;: [0.0, 0.05,\n",
       "                                                                  0.1],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1500, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                      &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25, 30, 35,\n",
       "                                                      40, 45, 50, 55, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_impurity_decrease&#x27;: [0.0, 0.05,\n",
       "                                                                  0.1],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1500, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['squared_error',\n",
       "                                                      'absolute_error'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 25, 30, 35,\n",
       "                                                      40, 45, 50, 55, None],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_impurity_decrease': [0.0, 0.05,\n",
       "                                                                  0.1],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1500, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "rf_base = RandomForestRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter = 200, cv = 3,verbose = 2, random_state = 42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 6,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50,\n",
       " 'criterion': 'squared_error',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164460030979933"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final model, which we train on the entire training set and test on the up until this point completely unseen test data, we will use the above hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation for Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Extreme Gradient Booster We will try to change the following hyperparameters: n_estimators, max_depth, min_child_weight, tree_method, eta, objective, n_thread, seed, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
    "\n",
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
    "\n",
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "\n",
    "# Learning rate\n",
    "xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n",
    "\n",
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
    "\n",
    "# Learning objective used\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
       " 'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " 'eta': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6],\n",
       " 'gamma': [0, 0, 0, 0, 0, 0],\n",
       " 'objective': ['reg:squarederror', 'reg:squaredlogerror'],\n",
       " 'tree_method': ['auto', 'hist']}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the grid\n",
    "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
    "            'max_depth': xgb_max_depth,\n",
    "            'min_child_weight': xgb_min_child_weight,\n",
    "            # 'tree_method': xgb_tree_method,\n",
    "            'eta': xgb_eta,\n",
    "            'gamma': xgb_gamma,\n",
    "            'objective': xgb_objective,\n",
    "            'tree_method': ['auto', 'hist']}\n",
    "\n",
    "xgb_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the strengths of Extreme Gradient Boosting is execution speed, it tends to be much faster than Random forest models, which is why the random grid search is completed a lot quicker for XGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;eta&#x27;: [0.1, 0.2, 0.30000000000000004,\n",
       "                                                0.4, 0.5, 0.6],\n",
       "                                        &#x27;gamma&#x27;: [0, 0, 0, 0, 0, 0],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14,\n",
       "                                                      16, 18, 20],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000],\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;reg:squaredlogerror&#x27;],\n",
       "                                        &#x27;tree_method&#x27;: [&#x27;auto&#x27;, &#x27;hist&#x27;]},\n",
       "                   random_state=420, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;eta&#x27;: [0.1, 0.2, 0.30000000000000004,\n",
       "                                                0.4, 0.5, 0.6],\n",
       "                                        &#x27;gamma&#x27;: [0, 0, 0, 0, 0, 0],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14,\n",
       "                                                      16, 18, 20],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000],\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;reg:squaredlogerror&#x27;],\n",
       "                                        &#x27;tree_method&#x27;: [&#x27;auto&#x27;, &#x27;hist&#x27;]},\n",
       "                   random_state=420, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'eta': [0.1, 0.2, 0.30000000000000004,\n",
       "                                                0.4, 0.5, 0.6],\n",
       "                                        'gamma': [0, 0, 0, 0, 0, 0],\n",
       "                                        'max_depth': [2, 4, 6, 8, 10, 12, 14,\n",
       "                                                      16, 18, 20],\n",
       "                                        'min_child_weight': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000],\n",
       "                                        'objective': ['reg:squarederror',\n",
       "                                                      'reg:squaredlogerror'],\n",
       "                                        'tree_method': ['auto', 'hist']},\n",
       "                   random_state=420, verbose=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "xgb_base = XGBRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n",
    "                                n_iter = 200, cv = 3, verbose = 2, \n",
    "                                random_state = 420, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'hist',\n",
       " 'objective': 'reg:squarederror',\n",
       " 'n_estimators': 1600,\n",
       " 'min_child_weight': 7,\n",
       " 'max_depth': 20,\n",
       " 'gamma': 0,\n",
       " 'eta': 0.4}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the optimal parameters\n",
    "xgb_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally using the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the performance of the three different models used in this analysis and performing hpyerparameter tuning, it's time to try out how good these models really are, this time using the test set for evaluating model performance.\n",
    "\n",
    "In what follows We will train the models on the entire 80% of the original dataset as the training set and test it on the 20% hold out set that we have not touched up until now. We will use the optimal hyperparameters found through randomised grid search for Random Forest and Extreme Gradient Booster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final multiple linear regression\n",
    "mlr_final = LinearRegression()\n",
    "\n",
    "# Create the final Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators = 200,\n",
    "                                 min_samples_split = 6,\n",
    "                                 min_impurity_decrease = 0.0,\n",
    "                                 max_features = 'sqrt',\n",
    "                                 max_depth = 25,\n",
    "                                 criterion = 'absolute_error',\n",
    "                                 bootstrap = True,\n",
    "                                 random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fnal Extreme Gradient Booster\n",
    "xgb_final = XGBRegressor(tree_method = 'exact',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         n_estimators = 1600,\n",
    "                         min_child_weight = 6,\n",
    "                         max_depth = 8,\n",
    "                         gamma = 0,\n",
    "                         eta = 0.1,\n",
    "                         random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(criterion=&#x27;absolute_error&#x27;, max_depth=25,\n",
       "                      max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;absolute_error&#x27;, max_depth=25,\n",
       "                      max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(criterion='absolute_error', max_depth=25,\n",
       "                      max_features='sqrt', min_samples_split=6,\n",
       "                      n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the models using 80% of the original data\n",
    "mlr_final.fit(X_train_temp, y_train_temp)\n",
    "rf_final.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "             max_leaves=None, min_child_weight=6, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1600,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "             max_leaves=None, min_child_weight=6, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1600,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "             max_leaves=None, min_child_weight=6, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1600,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final XGB using 80% of the original data\n",
    "xgb_final.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        mae = round(mean_absolute_error(test_labels, predictions), 4)\n",
    "        mse = round(mean_squared_error(test_labels, predictions), 4)\n",
    "        r2 = round(r2_score(test_labels, predictions), 4)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = round(100 - mape, 4)\n",
    "        scores[str(model)] = [mae, mse, r2, accuracy]\n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.9623</td>\n",
       "      <td>1.9246</td>\n",
       "      <td>2.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>6.4451</td>\n",
       "      <td>6.0908</td>\n",
       "      <td>9.0791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>97.5790</td>\n",
       "      <td>97.6193</td>\n",
       "      <td>97.2408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Linear Regression  Random Forest  \\\n",
       "Mean Absolute Error             1.9623         1.9246   \n",
       "Mean Squared Error              6.4451         6.0908   \n",
       "R^2                             0.7888         0.8004   \n",
       "Accuracy                       97.5790        97.6193   \n",
       "\n",
       "                     Extreme Gradient Boosting  \n",
       "Mean Absolute Error                     2.2042  \n",
       "Mean Squared Error                      9.0791  \n",
       "R^2                                     0.7025  \n",
       "Accuracy                               97.2408  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=5, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=2, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=2, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=2, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=2, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=7, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=4, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=3, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=2, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=4, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=9, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=6, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=7, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=6, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=6, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=2, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1200, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=10, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=6, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=5, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=5, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=5, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=4, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=2, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=10, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=8, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=10, n_estimators=600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=9, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=1, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=4, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1800, objective=reg:squarederror, predictor=auto, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=1, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=6, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=8, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=6, n_estimators=1800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=6, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=9, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=1, n_estimators=600, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1600, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=3, n_estimators=200, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, predictor=cpu_predictor, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=7, n_estimators=800, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1000, objective=reg:squarederror, predictor=cpu_predictor, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squarederror, predictor=auto, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1800, objective=reg:squarederror, predictor=cpu_predictor, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squarederror, predictor=auto, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=9, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=6, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=5, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=2, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=1, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=5, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=7, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=6, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=6, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=4, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=10, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "# Call the comparison function with the three final models\n",
    "final_scores = final_comparison([mlr_final, rf_final, xgb_final], X_test, y_test)\n",
    "final_scores.columns  = ['Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']\n",
    "final_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
